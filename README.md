# ğŸ· Wine Quality Prediction using Random Forest

## ğŸ“Œ Overview
This project implements a **Random Forest Classifier** to predict the quality of wine based on various chemical and physicochemical properties. The goal is to build a robust classification model that can assist in automating wine quality assessment, which traditionally relies on human tasting.

---

## ğŸ“Š Dataset

The dataset is sourced from the **UCI Machine Learning Repository** and contains **red wine samples**. Each row represents a wine sample with the following features:

### ğŸ”¬ Features:
- **Fixed Acidity** â€“ Tartaric acid content
- **Volatile Acidity** â€“ Acetic acid content (high levels cause vinegar taste)
- **Citric Acid** â€“ Acts as a preservative
- **Residual Sugar** â€“ Amount of sugar remaining after fermentation
- **Chlorides** â€“ Salt content
- **Free Sulfur Dioxide** â€“ Prevents microbial growth
- **Total Sulfur Dioxide** â€“ Sum of free and bound forms
- **Density** â€“ Related to sugar and alcohol content
- **pH** â€“ Acidity level
- **Sulphates** â€“ Additive contributing to sulfur dioxide levels
- **Alcohol** â€“ Alcohol content in % volume
- **Quality (Target)** â€“ Score between 0 and 10 (based on sensory data)

## ğŸ§  Model & Approach

### ğŸ” Exploratory Data Analysis (EDA)
- **Visualized feature distributions** using Seaborn histograms and KDE plots.
- **Plotted correlations** with a heatmap to identify strongly related features.
- Detected **outliers** and **missing values** (if any).
- Boxplots and scatterplots used to understand relationships with the target.

### âš™ï¸ Feature Engineering
- Applied **MinMaxScaler** to normalize features.
- Converted the **'quality'** variable into categorical labels (optional step).
- Handled **class imbalance** by analyzing distribution of quality scores.

### ğŸŒ² Machine Learning Model
- Implemented a **Random Forest Classifier** from scikit-learn.
- Performed **hyperparameter tuning** 
- Used **train_test_split** for model validation.

### ğŸ“ˆ Evaluation Metrics
- **Accuracy**: Overall correctness
- **Precision & Recall**: For each class
- **F1-Score**: Harmonic mean of precision and recall
- **Confusion Matrix**: For visualizing misclassifications
- **Feature Importance**: Determined which features influenced predictions most

ğŸ“Œ Model achieved an accuracy of approximately **92.6%** 

---

## âš™ï¸ Installation & Requirements

Make sure you have Python 3.x installed. Then install the following packages:

```bash
pip install numpy pandas scikit-learn seaborn matplotlib

